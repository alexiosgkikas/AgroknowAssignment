{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "from bs4 import BeautifulSoup \n",
    "import os \n",
    "\n",
    "#current dir\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e835d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.mhlw.go.jp/stf/seisakunitsuite/bunya/kenkou_iryou/shokuhin/yunyu_kanshi/index_00017.html\"\n",
    "BASE = \"https://www.mhlw.go.jp\"\n",
    "#current dir\n",
    "cwd = os.getcwd()\n",
    "#directroy path to save all downloaded xls \n",
    "SAVE_EXCEL_DIR = cwd+\"/xls/\"\n",
    "#save directory of json\n",
    "SAVE_EXCEL_DIR = cwd+\"/json/\"\n",
    "# yeard div in html page\n",
    "year_div = \"m-hdgLv3__hdg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d772e",
   "metadata": {},
   "source": [
    "## SubTask 1\n",
    "For the First task libraries like urlib and BeautifulSoup , so could extract the urls and download teh xls files and save them in folder with name /xls/ with format Year_Month.xls ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0d16f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "    Function that check if the excel already was parsed\n",
    "    \n",
    "    parameters:\n",
    "            \n",
    "            resp: respone of url \n",
    "            \n",
    "            mode: which mode would be follow when downloading xls. \n",
    "                0: Download only new xls\n",
    "                1: redownload all\n",
    "\"\"\"\"\"\n",
    "\n",
    "def get_urls_list(resp,mode= 0):\n",
    "    excels = dict() #create a dictionary of years\n",
    "    \n",
    "    soup = BeautifulSoup(resp.text)\n",
    "    year  = soup.find_all(\"h3\", {\"class\": year_div}) #get all years\n",
    "    tables = soup.find_all(\"table\")#\n",
    "    \n",
    "    #for each table of the year\n",
    "    for t in  range(0,len(tables)): \n",
    "        yearly_xls = dict() #create a dictionary for each year, with  {month:urls of xls} \n",
    "        for month in tables[t].find_all(\"td\"):\n",
    "            if (month.find('a')) and (month.find('a').get('href').endswith('xls')):\n",
    "                #print(\"year: \",year[t].text ,\" , \",month.next_element.strip()  ,\" : \", month.find('a').get('href'))\n",
    "                yearly_xls[month.next_element.strip()] = BASE+month.find('a').get('href') \n",
    "        \n",
    "        excels[year[t].text] = yearly_xls # add each dictionary of year in another dictionary\n",
    "    \n",
    "    return excels\n",
    "\"\"\"\"\"\n",
    "    Function that download xls from given urls\n",
    "    \n",
    "    parameters:\n",
    "            \n",
    "            urls: list off all urls\n",
    "            \n",
    "            mode: which mode would be follow when downloading xls. \n",
    "                0: Download only new xls, that doesn exits in xls folder\n",
    "                1: redownload all found xls\n",
    "\"\"\"\"\"\n",
    "\n",
    "def download_xls(urls, mode):\n",
    "    for y in urls.items():\n",
    "        print(\"Downloading xls for year: \"+y[0])\n",
    "        for m in y[1].items():\n",
    "            filename = SAVE_EXCEL_DIR+y[0]+'_'+m[0]+'xls'\n",
    "            if os.path.isfile(filename) and mode == 0:\n",
    "                print (\"File exist. No action would take.\")\n",
    "            else:\n",
    "                print (\"File does not exist or mode is on overwrite.Creating new xls for Month \"+m[0])\n",
    "                resp = requests.get(m[1])\n",
    "                try:\n",
    "                    with open(SAVE_EXCEL_DIR+y[0]+'_'+m[0]+'xls', 'wb') as file:\n",
    "                        file.write(resp.content)\n",
    "                except IOError:\n",
    "                    print(\"Unable to create file on disk.\")\n",
    "\n",
    "                    \n",
    "                    \n",
    "if __name__ == \"__main__\":\n",
    "    resp = requests.get(URL)\n",
    "    urls = get_urls_list(resp)\n",
    "    download_xls(urls,mode= 0)  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ff21cd",
   "metadata": {},
   "source": [
    "## SubTask 2\n",
    "1. For the 2nd Task  the function get_xls checks for the given folder all files and return them.\n",
    "2.  Function create_json get each file and transform it to json. The json file has the format of the table, with nested items only the row as a list,like example below and save in folder /json/:\n",
    "    { \"YEAR\" : 2011,\n",
    "       \"Month\" : \"Apr\",\n",
    "       \"ITEMS\" :\\[{row1},{row2},... \\]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4a1b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_xls(path):\n",
    "    files = os.listdir(path)\n",
    "    for f in files:\n",
    "        print(f)\n",
    "    return files\n",
    "\n",
    "def create_json(filename, json_folder = SAVE_JSON_DIR):\n",
    "    year,month = os.path.splitext(os.path.basename(filename))[0].split('_')\n",
    "    print(year,month)\n",
    "    df = pd.read_excel(filename,header = 1)\n",
    "    # converting the string to datetime format\n",
    "    #return None\n",
    "    json_str = df.to_json(orient='records')\n",
    "    str_json = '{ \"YEAR\":'+'2011'+','+'\"MONTH\":\"'+'Apr'+'\",\"ITEMS\":'+json_str+\"}\" \n",
    "    #print(str_json)\n",
    "    \n",
    "    savefilename = year+'_'+month+'.json'\n",
    "    with open(json_folder+savefilename,'w') as file:\n",
    "        file.write(str_json)\n",
    "\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    xlsFiles = get_xls(SAVE_EXCEL_DIR)\n",
    "    for f in xlsFiles:\n",
    "        create_json(filename = SAVE_EXCEL_DIR+f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eccf87c",
   "metadata": {},
   "source": [
    "## Subtask 3\n",
    "The 3rd Subtask was not implemented, but here the approach that would follow:\n",
    " 1. clear data from unessary columns like publication date and remarks.\n",
    " 2. For Feautures extraction in column \"CONTENTS OF VIOLOTAION\" word embedings like doc2vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6780aaa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
